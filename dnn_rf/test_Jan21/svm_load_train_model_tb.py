# Load a dnn model from .pb file
# Train and test model using data from file training_set

# Input: 
# 1. files generated by make_dnn.py 
# 2. training_set (may need to modify the inputfile path)

from numpy import array
from numpy import argmax
import tensorflow as tf
import numpy as np
import os
import matplotlib.pyplot as plt
import sklearn.metrics as metrics
import time
from tensorflow.python.platform import gfile
from sklearn.datasets import load_svmlight_file
from sklearn import preprocessing
from tensorflow.contrib.tensor_forest.client import *
from tensorflow.contrib.tensor_forest.python import *
from tensorflow.python.ops import resources

start_time = time.time()
graph_pb = 'dnn_graph/model'

graph_def = tf.GraphDef()
export_dir = "dnn_trained/model"
# builder = tf.saved_model.builder.SavedModelBuilder(export_dir)


# with open(graph_pb, 'rb') as f:
# 	graph_def.ParseFromString(f.read())
# tf.import_graph_def(graph_def, name='')

sess = tf.InteractiveSession()
graph = tf.saved_model.loader.load(sess, ['tag'],graph_pb)


accuracy       = sess.graph.get_tensor_by_name('accuracy:0')
nbr_features   = sess.graph.get_tensor_by_name('nbr_features:0')
input_features = sess.graph.get_tensor_by_name('x:0')
input_labels   = sess.graph.get_tensor_by_name('y_:0')
keep_prob      = sess.graph.get_tensor_by_name('keep_prob:0')
loss_optimizer = sess.graph.get_tensor_by_name('loss_optimizer:0')
correct_prediction = sess.graph.get_tensor_by_name('correct_prediction:0')
init_op        = sess.graph.get_operation_by_name('init')

# tensorboard
tf.summary.scalar('accuracy', accuracy)
merged = tf.summary.merge_all()
train_writer = tf.summary.FileWriter('./TFlogs', sess.graph)

sess.run(init_op)

# first get the limits 
col_size = sess.run(nbr_features)
batch_size = 40
training_data = load_svmlight_file("../../../ps_data/train-0.svm")
Xr = training_data[0].todense()[:,0:col_size]
n = training_data[0].shape[0]
yr = training_data[1]
lb = preprocessing.LabelBinarizer()
yr = lb.fit_transform(training_data[1])
if input_labels.get_shape().as_list()[1] == 2:
	yr = np.column_stack([yr, 1-yr])

for v in tf.get_default_graph().as_graph_def().node:
	print (v.name)


for i in range(2):

	for j in range(int(n/batch_size)):
		batch_xs = Xr[j*batch_size: (j+1)*batch_size-1]
		batch_ys = yr[j*batch_size: (j+1)*batch_size-1]	
		sess.run(loss_optimizer, feed_dict={input_features: batch_xs, input_labels: batch_ys, keep_prob: 0.5})

	if i % 2 is 0:     
		print ('epoch: ' + str(i))
		summary,acc = sess.run([merged, accuracy], feed_dict={input_features: Xr, input_labels: yr, keep_prob: 1.0})
		train_writer.add_summary(summary,i)
		print (acc)

builder = tf.saved_model.builder.SavedModelBuilder(export_dir)
builder.add_meta_graph_and_variables(sess, ['tag'])
builder.save()
sess.close()

end_time = time.time()
print('run time: '+ str(round(end_time-start_time)) + ' seconds')

